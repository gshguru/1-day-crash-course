# Dive into Deep Learning in 1 Day

## Practical information

| | |
|---|---|
| Instructors | [Alex Smola](https://alex.smola.org) and [Mu Li](https://github.com/mli) |
| Time | July 9, 2019 |
| Locations | Arizona Event Venue at Arizona (SEA29) 1st Floor  |

## Overview

Did you ever want to find out about deep learning but didn't have time
to spend months? New to machine learning? Do you want to build image
classifiers, NLP tools, train on many GPUs or even on many machines?
If you're an engineer or data scientist, this course is for you.
This is about the equivalent of a Coursera course, all packed into one
day. The course consists of four segments of 90 minutes each.

1. Deep Learning Basics
1. Convolutional Neural Networks for computer vision
1. Best practices (GPUs, Parallelization, Fine Tuning, Transfer Learning)
1. Recurrent Neural Networks for natural language (RNN, LSTM, GRU)

## Prerequisites

You should have some basic knowledge of
[Linear Algebra](http://d2l.ai/chapter_appendix/math.html),
[Statistics](http://d2l.ai/chapter_crashcourse/probability.html), and
[Python](https://learnpythonthehardway.org/) (here's
[another book](https://www.diveinto.org/python3/) to learn
Python). Moreover, you should have some experience with
[Jupyter](https://jupyter.org/) notebooks, or with
[SageMaker](http://aws.amazon.com/sagemaker) notebooks. To run things
on (multiple) GPUs you need access to a GPU server, such as the
[P2](https://aws.amazon.com/ec2/instance-types/p2/),
[G3](https://aws.amazon.com/ec2/instance-types/g3/), or
[P3](https://aws.amazon.com/ec2/instance-types/p3/)
instances.

## Syllabus

This course relies heavily on the
[Dive into Deep Learning](http://d2l.ai) book. There's a lot more
detail in the book (notebooks, examples, math, applications). The
crash course will get you started. For more information also see [other
courses and tutorials](http://courses.d2l.ai) based on the book.

| Time | Topics |
| --- | --- |
| 8:00---9:00 | Setup clinic for laptops |
| 15min | [Introduction to Deep Learning](http://d2l.ai/chapter_introduction/intro.html) |
| 5min | [Installation](http://d2l.ai/chapter_install/install.html) |
| 5min | [Linear Algebra](http://d2l.ai/chapter_install/linear-algebra.html) |
| 5min | [Autograd](http://d2l.ai/chapter_crashcourse/autograd.html) |
| 10min | [Linear regression](http://d2l.ai/chapter_linear-networks/linear-regression.html) in [Gluon](http://d2l.ai/chapter_linear-networks/linear-regression-gluon.html) |
| 10min | [Optimization](http://d2l.ai/chapter_optimization/index.html) |
| 10min | [Softmax Regression](http://d2l.ai/chapter_linear-networks/softmax-regression.html) in [Gluon](http://d2l.ai/chapter_linear-networks/softmax-regression-gluon.html) |
| 10min | [Multi-layer Peceptron](http://d2l.ai/chapter_multilayer-perceptrons/index.html) (MLP) in [Gluon](http://d2l.ai/chapter_multilayer-perceptrons/mlp-gluon.html) |
| 20min | Train MNIST with MLP |
| 10:30---11:00 | Coffee break |
| 10min | [Use GPUs](http://d2l.ai/chapter_deep-learning-computation/use-gpu.html) |
| 20min | [Convolutional Layers](http://d2l.ai/chapter_convolutional-neural-networks/index.html) |
| 10min | [LeNet](http://d2l.ai/chapter_convolutional-neural-networks/lenet.html) and [AlexNet](http://d2l.ai/chapter_convolutional-modern/alexnet.html) |
| 10min | [VGG](http://d2l.ai/chapter_convolutional-modern/vgg.html) |
| 5min | [Batch Normalization](http://d2l.ai/chapter_convolutional-modern/batch-norm.html) |
| 10min | [ResNet](http://d2l.ai/chapter_convolutional-modern/resnet.html) |
| 25min | ResNet in Python |
| 12:30---2:00 | Lunch break |
| 15min | [Optimization Algorithms](http://d2l.ai/chapter_optimization/index.html) |
| 15min | [Multi-GPU Training](http://d2l.ai/chapter_computational-performance/multiple-gpus.html) |
| 15min | Distributed Training |
| 15min | [Deploy](http://beta.mxnet.io/guide/deploy/index.html) |
| 10min | [Hybridization](http://d2l.ai/chapter_computational-performance/hybridize.html) |
| 20min | [Fine tuning in Python](http://d2l.ai/chapter_computer-vision/fine-tuning.html) |
| 3:30---4:00 | Coffee break |
| 10min | [Sequence Modeling Basics](http://d2l.ai/chapter_recurrent-neural-networks/sequence.html) |
| 15min | Autoregressive Modeling in Python |
| 10min | Latent variable models   |
| 10min | [Data preprocessing for text](http://d2l.ai/chapter_recurrent-neural-networks/lang-model-dataset.html) |
| 15min | Latent variable models in Python |
| 10min | [Backpropagation through time](http://d2l.ai/chapter_recurrent-neural-networks/bptt.html) |
| 20min | [LSTM](http://d2l.ai/chapter_recurrent-neural-networks/lstm.html) and [GRU](http://d2l.ai/chapter_recurrent-neural-networks/gru.html) |
